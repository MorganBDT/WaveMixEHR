{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7ea1105-6f5f-438d-8431-10c7e0183f7f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pickle as pkl\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pdb\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aab3bd8-d78a-4fa5-9f68-7e7b39ea1fa6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_result_settings(result_dict):\n",
    "    \"\"\"\n",
    "    from result dict with [modality][feature_type][metric], return all the key values\n",
    "    Returns:\n",
    "       modalities (list), feature_types(list)\n",
    "    \"\"\"\n",
    "    modalities = []\n",
    "    feature_types = []\n",
    "    for modality, feature_type_dict in result_dict.items():\n",
    "        modalities.append(modality)\n",
    "        for feature_type in feature_type_dict:\n",
    "            feature_types.append(feature_type)\n",
    "    return [set(val) for val in [modalities, feature_types]]\n",
    "\n",
    "def get_unimodal_result_dict(task):\n",
    "    with open(f'../data/supervised_pipeline/{task}_performance_tracker.pkl', 'rb') as f:\n",
    "        result_dict = pkl.load(f) # [task][modality][feature_type][metric]\n",
    "    return result_dict\n",
    "\n",
    "def get_fusion_result_dict(task):\n",
    "    \"\"\"\n",
    "    actually this one should contain all the modalities\n",
    "    \"\"\"\n",
    "    with open(f'../data/supervised_pipeline/{task}_late_fusion_performance_tracker.pkl', 'rb') as f:\n",
    "        result_dict = pkl.load(f)\n",
    "    return result_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93e83db6-c977-49b9-ab18-00ef2a703883",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "BASE_DIR = '../data/'\n",
    "TASKS = ['los', 'mort']\n",
    "metric = 'auc'\n",
    "BAR_WIDTH = 0.2\n",
    "\n",
    "for task in TASKS:\n",
    "    result_dict = get_unimodal_result_dict(task)\n",
    "    modalities, feature_types = get_result_settings(result_dict)\n",
    "    xticks = modalities\n",
    "    #pdb.set_trace()\n",
    "    xtick_pos = np.arange(len(xticks))\n",
    "    colors = [plt.cm.tab20(j) for j in range(len(feature_types))]\n",
    "    fig, ax = plt.subplots()\n",
    "    for j, feature_type in enumerate(feature_types):\n",
    "        metrics = [result_dict[modality][feature_type][metric] for modality in modalities if feature_type in result_dict[modality]]\n",
    "        ax.bar(xtick_pos + j * BAR_WIDTH, metrics, width=BAR_WIDTH, label=feature_type)\n",
    "        [ax.text(xtick_pos[i] + j * BAR_WIDTH, value + 0.01, f'{value:.3f}', ha='center') for i, value in enumerate(metrics)] \n",
    "    # Set the xticks and labels\n",
    "    ax.set_xticks(xtick_pos)\n",
    "    ax.set_xticklabels(xticks)\n",
    "\n",
    "    # Set the y-label and the title\n",
    "    ax.set_ylabel('AUC')\n",
    "    ax.set_title(f'{task.upper()} Predictions')\n",
    "    ax.set_ylim(0, 1)\n",
    "\n",
    "    # Add the legend\n",
    "    ax.legend(loc='lower left')\n",
    "\n",
    "    # Show the plot\n",
    "    plt.show()\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcfbea50-84a8-4aa0-b562-b565ca018577",
   "metadata": {},
   "source": [
    "# let's not get too fancy. just make a table of results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cceffe2d-ac33-49e8-8b35-b1f625adc367",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from collections.abc import Iterable\n",
    "for task in TASKS:\n",
    "    result_dict = get_fusion_result_dict(task)\n",
    "    modalities, feature_types = get_result_settings(result_dict)\n",
    "    # create empty lists to store the values for each column\n",
    "    modality_list = []\n",
    "    setting_list = []\n",
    "    metrics_dict = {}\n",
    "    for modality, settings_dict in result_dict.items():\n",
    "        # loop through the inner keys (settings) for each modality\n",
    "        for setting, metrics in settings_dict.items():\n",
    "            # append the values to the corresponding lists\n",
    "            modality_list.append(modality)\n",
    "            setting_list.append(setting)\n",
    "            # update the metrics dictionary with any new metrics\n",
    "            metrics = {metric: val for metric, val in metrics.items() if not isinstance(val, Iterable)}\n",
    "            for metric, val in metrics.items():\n",
    "                if metric not in metrics_dict:\n",
    "                    metrics_dict[metric] = []\n",
    "                metrics_dict[metric].append(val)\n",
    "\n",
    "    # create the DataFrame from the lists and metrics dictionary\n",
    "    # rename modality list\n",
    "    renamed_modalities = []\n",
    "    renamed_settings = []\n",
    "    for modality in modality_list:\n",
    "        if modality == 'ecg':\n",
    "            renamed_modalities.append('ecg feats')\n",
    "        else:\n",
    "            renamed_modalities.append(modality.replace('_', ' '))\n",
    "    for setting in setting_list:\n",
    "        split_name = setting.split('-')\n",
    "        topic_name = 'topics(' + split_name[-1] + ')'\n",
    "        if len(split_name) > 1:\n",
    "            ecg_name = 'ecg feats + '\n",
    "        else:\n",
    "            ecg_name = ''\n",
    "        renamed_settings.append(ecg_name + topic_name)\n",
    "    df = pd.DataFrame({\n",
    "        'modality': renamed_modalities,\n",
    "        'setting': renamed_settings,\n",
    "        **metrics_dict\n",
    "    })\n",
    "\n",
    "    # print the resulting DataFrame\n",
    "    print(f'task: {task}')\n",
    "    print(df.to_string(index=False))\n",
    "    print(df.to_latex(index=False, float_format=\"%.3f\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d4bedcb-e6cb-4023-9cd0-375d28da49cf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# make it latex\n",
    "print(df.to_latex(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7547d90c-2296-40f6-9bd1-ead30bf21e56",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77216b3f-6244-4fea-80d7-baf21fa6f4ac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
